\SECTION{Introduction}
Graphics Processing Units (GPUs) are being used at an increasing frequency to accelerate various applications,
navigation~\cite{cmu:routing} for autonomous driving, object detection~\cite{hirabayashi:cpsna2013},
tokamak control for fusion reactors~\cite{tokamak},
user-interactive applications~\cite{kato:rtas2011}, databases~\cite{bakkum:sql}, and various benchmarks~\cite{rodinia} that contain many other applications.
GPU performance has been demonstrated by such research.

Previously, GPU applications were required to be only ``real-fast'' because they were best effort oriented.
Recent GPU applications are required to be both ``real-time'' and ``real-fast'' due to an increasing number of real-time oriented applications that target real-world problems.

GPUs runtime environments, such as CUDA~\cite{nvidia:cuda_zone} and OpenCL~\cite{opencl} 
primarily target  best-effort applications; thus, they do not support real-time requirements.
Therefore, GPU runtime environments must support real-time scheduling.

In our previous work,
we showed how to support GPU resource management\cite{kato:timegraph,kato:gdev}.
TimeGraph~\cite{kato:timegraph} provides GPU scheduling and reservation mechanisms at the device driver level to queue and dispatch GPU commands based on task priorities.
Gdev~\cite{kato:gdev} is a resource management system.
However, these methods have a weak point; they do not provide fast update architecture and full-functionality
because these methods are based on reverse engineering.

In GPU environments,
GPU functions are provided by an API of a library and the application binary interface (ABI) of device drivers.
Note that CPU time is consumed when GPU kernels are issued by the API or ABI.
Thus, if GPUs are to truly satisfy real-time requirements,
host-side task management and GPU resource management are required.
We have confirmed that a large amount of latency occurs
when other tasks appropriate resources at the host side~\cite{fujii:icpads2013} evaluate the data transfer time between host memory and device memory.

GPUSync~\cite{elliott:gpusync13,elliott:explor14} proposed by Elliott et al. provides CPU task scheduling for multiple GPU aware and budget enforcement on the proprietary runtime.
GPUSync realizes a configurable framework that can verify the combination of task allocation policies for multi-core and multi-processor CPUs and GPU kernel allocaton policies for multiple GPUs.

However, GPUSync is implemented using $LITMUS^{RT}$~\cite{litmus}, which introduces a significant amount of changes to the kernel.
Gdev also requires the modification of the device driver.
Many of these modifications require the user install patches, which introduces a significant burden to both developers and users.
Specifically, developers are obliged to maintain patches in order to stay up to date with the latest kernel releases.
However, open source software (e.g., Linux) is commonly update before, developers can complete porting their work to the latest kernel.

Linux supports the loadable kernel module (LKM), which can load/unload kernel modules to provide additional kernel functions.
We employ the LKM real-time extension called RESCH\cite{kato2009loadable}.
RESCH provides a real-time scheduling framework but does not modify the kernel and device drivers.
Note that RESCH does not support scheduling of GPU resources.

\textbf{Contribution:}
This paper presents a Linux loadable real-time extension for CPU and GPU resource coordination
called the Linux real-time extension including GPU resource management (Linux-RTXG).
This extension can easily re-configure a resource management algorithms and easily install framework.
Linux-RTXG's most significant contribution is the achievement of real-time task scheduling of a GPU environment without kernel modification.
To achieve this, 
Linux-RTXG provides a CPU task scheduler, a GPU kernel scheduler, and GPU kernel reservation mechanisms.
The CPU task scheduler is based on RESCH.
The GPU kernel scheduler and the GPU kernel reservation mechanisms are based on Gdev.
They are integrated in Linux-RTXG using a kernel modification free approach that does not modify the  kernel or device driver source code.

\textbf{Organization}
The rest of this thesis is as follows.
Section~\ref{sec:system_model} discusses the kernel modification free GPU real-time scheduling.
Section~\ref{sec:design_imple} presents the design and implementation of Linux-RTXG with specific focus on GPU scheduling.
Section~\ref{sec:evaluation} discusses Linux-RTXG's  advantages and dis-advantages, and presents experimental results(i.e., quantitative overhead and reservation performance).
Section~\ref{sec:relatedwork} discusses related work, and we present concluding remarks in Section~\ref{sec:conclusion}.
