\section{System Model}\label{sec:system_model}
In this section, we explain GPU task model in this paper, and also we discuss the GPU scheduling and prior works.
Next, we make available limitation for clearing the implementation of GPU scheduling without kernel modification.
This paper focuses on a system composed of multiple GPUs and multi-core CPUs.

\subsection{GPU Task Model}
In case of General Purpose GPU computing (GPGPU), CUDA and OpenCL are used to implement GPU applications.
This paper focuses on CUDA, but this paper approach is possible to adapt the same approach to OpenCL.

We define a GPU task as a process wich executes GPU,
which cyclic executes unit is called GPU job,
and, a GPU kernel is a processing to be executed on the GPU side.
We support that a GPU application has multiple tasks.

GPUs use a set of the API supported by the runtime environment such as CUDA,
typically GPU application takes the following steps:
(i) \textit{cuCtxCreate} creates a GPU context,
(ii) \textit{cuMemAlloc} allocates memory spaces to device memory, 
(iii) \textit{cuModuleLoad} and \textit{cuMemcpyHtoD} copy the data and the GPU kernel to the allocated device memory spaces from host memory spaces,
(iv) \textit{cuLaunchGrid} invokes the GPU kernel, 
(v) \textit{cuCtxSynchronize} synchronizes waiting GPU task to that is completion of kernel, 
(vi) \textit{cuMemcpyDtoH} transfers resultant data to host memory from device memory, and
(vii) \textit{cuMemFree}, \textit{cuModuleUnload}, and \textit{cuCtxDestroy} release allocated memory spaces and the GPU context.


%我々は本稿においては、GPU実行が少しでも含まれるプロセスであり、ある事柄を成し遂げる一つの単位をアプリケーションとする。 (e.g. pedestrian detection application).
%またこの一連の流れによってGPUを実行する1プロセスをGPUタスクとし、
%GPU側で実行されるカーネルをGPUカーネルと定義する。

\subsection{GPU Scheduling}
Real-time OS (RTOS) researches~\cite{spring,redline,itron,rk} have been conducted for a long time.
In among them, there are many existing studies concerning RTOS based on Linux~\cite{litmus,prk,rtai,yodaiken1999rtlinux,kato2009loadable}.
%リアルタイムOSは古来より多くの研究~\cite{spring,redline,itron,rk}が行われてきてい。
%LinuxをベースとしたリアルタイムOSとしても数多く研究~\cite{prk,rtai,yodaiken1999rtlinux,litmus,kato:loadable}されている。
%GPUを利用可能な環境はWindows, Mac OS, Linuxと限られており、リアルタイムという性質を追求するためにはLinuxの利用が最適であるため、今回我々はlinuxを利用する。
The available OS for GPUs are limited to Windows, Mac OS and Linux.
We selected Linux in order to achieve real-time processing on GPU environments.

In order to meet real-time constraints on shared resource environment such as a multicore environment,
there are two requirements for the scheduler as follows:
%マルチコア環境でリアルタイムを実現するにあたりスケジューラが最低限必要とする要件は以下の2つである．
\begin{itemize}
\item To use resources according to a specified order
%.The mechanisms is resources that are available to the specified order
%u指れた順番でリソースが利用可能なこと
\item To limit the use of the shared resources
\end{itemize}
A basic approach of the previous works to satisfy the first requirement uses priority-based scheduling (e.g. Rate-Monotonic~\cite{sched:rm} and Earliest Deadline First~\cite{sched:edf}) with technique to prevent priority inversion,
and the second one is resource reservation-based scheduling (e.g. Constant Bandwidth Server~\cite{rr:cbs}, Total Bandwidth Server~\cite{rr:tbs2}).
%これらを満たすための基本的なアプローチとして，一つ目は優先度ベースのスケジューリング (e.g. Rate-monotonic, Earliest deadline first)，
%2つ目は，リソースリザベーションベースのスケジューリング (e.g. CBS, TBS, credit)が用いられる．
GPUs need to handle a data transfer bandwidth and a processing core as a shared resource;
thus, we satisfy the two requirements similar to above multicore environment.
%GPUはデータ転送帯域，プロセッシングコアの2つを共有リソースとして扱う必要性があり，上記マルチコア環境と同様に2つの要件を満たす必要がある．
%Therefore, in the system of including GPU is 
%そのためGPUが含まれるシステムにおいても，リアルタイムを実現するためには上記二点を達成できればよい．
Our previous works schedule only GPU accesses. 
However, GPU kernel consumes CPU time because GPU task driven by API.
In order to truly support the real-time scheduling, scheduler is need to schedule GPU tasks of CPU cide.
Therefore, the framework needs to have CPU's priority-based scheduler, GPU's priority-based scheduler, and GPU's resource reserbation mechanism to realize real-time GPU
%我々がこれまで取り組んできたGPUリソースマネージメントに関する研究では，
%GPUへのアクセスのみをスケジューリングしてきた．
%しかしながらGPUカーネルはGPUタスクから発行されるAPIを起点に動作していることから，
%真にリアルタイムスケジューリングを適応するためには，GPUタスク自体のスケジューリングを行う必要がある．
%したがって，GPUをリアルタイムにスケジューリングするために必要なメカニズムは，
%CPUの優先度ベーススケジューラ，GPUの優先度ベーススケジューラ，リソースリザベーションによるGPUリソース制限である．
Recently, GPUSync target interdependence of CPU scheduler and GPU scheduler.
%最近ではGPUSyncが上記のCPUスケジューラとGPUスケジューラの相互依存について取り組んでいる．

%しかし，GPUSyncは$LITMUS^RT$に依存しており，パッチによるインストレーションを必要とする．
%Section~\ref{sec:intro}で述べたとおり，カーネルにパッチを当てる作業は大きな負担になる．
GPUs have some problems on real-time environment, except  scheduling mechanisms.
GPUs runtime environments are black-box mechanisms results from GPU environments are provided only GPU vendors, and these environments are closed-source.
TimeGraph and Gdev address this problem by ensure transparency using reverse engineering and an open-source driver.
GPUSync achieve closed-source compatible by GPU resource management that approaches are the interrupt handling and the arbitrate runtime access.
%GPUのリアルタイム活用にはスケジューリングメカニズム以外の面でも多くの問題がある．
%まずGPUの実行環境がベンダーから提供されるのみであり，クローズドソースになっていることからブラックボックスであることである．
%本問題についてはTIMEGRAPH，GDEV，RGEMではリバースエンジニアリングとオープンソースドライバによって透明性を確保している．
%GPUSyncではランタイムドライバへのアクセスを単一に制限することで，ランタイムドライバが行う資源管理をスルーしている．

The other problem occurs by non-preemptive GPU executions and non-preemptive data transfers.
Several researches~\cite{basaran:preemptive,sparc} have improvemed the response time by preventing overrun which occurs while dividing the kernel.
%GPUの実行やデータ転送がノンプリエンプティブであることも大きな問題だ．いくつかの研究~\cite{}ではカーネルを分割することで，
%ノンプリエンプティブに起因するオーバランを防ぎ，レスポンスタイムの向上を実現している．
%As these core problems are on the process of being resolved,
However, these existing methods concerning real-time GPU are typically experimental, not practical enough.
%このようにいくつかのコアな問題は解決に近づいているが，未だリアルタイムGPUは実験フェーズであり，実用化に向けるには問題が存在している．
The most difficult problem is self-suspending because GPU is treated as an I/O device.
GPU tasks suspend until it receives the results from invoking the processing to GPU, referred to as self-suspension.
%GPUを完全にリアルタイムに扱うことができないもっとも困難な問題は，GPUがI/Oデバイスとして扱われることに起因する．
%GPUに処理を発行し，結果を受け取るまでの間，発行したタスクは自らサスペンドする．
The self-suspension has been proven as a cause the NP-HARD problem in previous work~\cite{self-sus:1,self-sus:2},
several researches~\cite{chattopadhyay2014limited,kim2013segment} are working on the scheduling analysis for self-suspension task,
they have not been solved yet completely.

Hence, the proposed scheduling framework aims at easier expansion and installation.
%このself-suspensionはこれまでの研究~\cite{self-sus:1,self-sus:2}でNP-HARDな問題を発生させるとして証明されており，
%これまでも多くの研究が執り行われている~\cite{chattopadhyay2014limited,kim2013segment}が，実用レベルでは未だ解決されていない問題である．
%そのため本研究で目指すような拡張，インストールを容易とするスケジューリングフレームワーク実験レベル，実用レベルの両者において有用であり，需要が発生すると推測する．

\textbf{GPU Synchronization:}
%GPUを利用するシステムのようなヘテロジニアス且つメモリを共有しない場合に大きな課題となるのが同期である
The synchronization must be considered for GPU system such as heterogeneous platform.
GPU have two different synchronization technique.
The first techniques is memory map based synchronization which is called FENCE,
FENCE sends GPU commands after the command to take action,
then GPU microcontrollers will write the any value to a memory-mapped space after action is completed.
A GPU task monitors the mapped space value using such as polling.
Therefore task has an exclusive CPU resource,
but response time will be the fastest.
The other techniques is interruption based synchronization which is called NOTIFY.
NOTIFY sends GPU commands similar to FENCE,
then GPU microcontrollers will rise the interrupt and write any value to GPU I/O registers.
A GPU task is suspending until interrupt.
Therefore a task is able to share the CPU resources with other tasks,
but a response time will be the slow.
A Detailed architecture is omitted in this paper,
and the detailed architecture has been described in the previous documents~\cite{kato:timegraph, kato:gdev, fujii:apsys2013}.

Gdev uses both techniques, NOTIFY and FENCE for wakeup the waiting task, 
and NOTIFY is used by scheduler, FENCE is used by kernel synchronization. 
In Gdev, synchronization implementation is the additional commands sends to GPU and the modification of device driver's interrupt handler.
GPUSync uses NOTIFY technique by using tasklet intercept~\cite{elliott2012robust} on the proprietary software.
Tasklet is Linux's soft-irq implementation.
GPUSync identifies the interrupt that is invoked kernel by callback pointer with a tasklet.

\textbf{kernel free scheduler:}
We must not modify the kernel code and the device driver code to achieve ``kernel free''.
GPU scheduler is required to receive a notice of GPU kernel completion, for selection of next executing GPU kernel.
It is realized by two methods that are API-driven method and Interrupt-driven method.
The API-driven method is explicitly wakeup the scheduler after the synchronized by API such as $cuCtxSynchronize()$ provided runtime in the RGEM.
The Interrupt-driven method is woken up by a trigger of the interrupt which is issued by using NOTIFY in the Gdev and TimeGraph.
General utilized $cuCtxSynchronize()$ synchronize completion of all GPU kernels.
Therefore, API driven is able to use when a GPU context have issued only single kernel.
Thus, if a GPU task invokes multiple kernels, we must use the Interrupt-driven method for not to guarantee overrun due to reduction of the response time.

%GPU スケジューラは次に実行するカーネルの 選択のために,
%現在実行中のカーネルの実行が終了したという通知を受け取る必要がある.
%この受 取には,API-driven と Interrupt-driven な方式が ある.RGEM ではこの API-driven を用いており, cuCtxSynchronize() などのランタイムによって 提供される API によってカーネルが同期された後 に,明示的にスケジューラを起動する API を発行 する.Gdev や TimeGraph では Interrupt-driven を利用しており,NOTIFY を利用する際に発行さ れる割込みをトリガーとしてスケジューラを起動 する.
%一般的に用いられる cuCtxSynchroniza() は当 該コンテキストで現在発行されている全てのカー ネルが終了したタイミングで同期する.したがっ て API-driven では一つの GPU コンテキストから は一度に一つのカーネルが発行される場合のみに 対応可能である.
%しかしながら,一つの GPU コンテキストから 連続して複数のカーネルが発行されるケースは, 多々発生すると考えられる. その影響から,カー ネル実行のレスポンスタイムが低下し,オーバラ ンの発生率を高める問題が発生する.
The Interrupt-driven method can be synchronized for each kernel, and its method is required to modify the kernel or the device driver's ISR.
Gdev has been achieved independent synchronization mechanisms on the proprietary soft-ware,
the independent synchronization mechanisms are needed to modify the kernel modification.
The challenge is realizing independent synchronization mechanisms without kernel modification

%We define a GPU task which is to execute the GPU using above API flow,
%and define a GPU kernel that is unit of processing to executed on the GPU side.
%Interrupt-driven では NOTIFY で用いられる割 込みを取得するため,各カーネル毎に同期が可能 であるため,スケジューリングを考えた場合には 有効であるが,割込みの取得のために,カーネル もしくはデバイスドライバ内の ISR を直接修正す る必要がある.
