\section{System Model}\label{sec:system_model}
In this section, we explain GPU task model on this paper while we discuss the gpu scheduling question and prior work.
Next, we make available limitation for clearing the implementation of no patched gpu scheduling.
This paper focus on a system composed of multiple GPU and multi-core CPU.

\subsection{GPU Task Model}
When using GPU in general-purpose way, CUDA and OpenCL can use much.
In this paper, we only use CUDA, but it is possible the same approach even OpenCL.

GPU applications use a set of the API supported by the system,
typically talking the following steps.
(i) create GPU context (\textit{cuCtxCreate}), 
(ii) allocate space to device memory (\textit{cuMemAlloc}), 
(iii) The data and the GPU kernel are copied to the allocated device memory space from host memory (\textit{cuMemcpyHtoD}), 
(iv) Launch the GPU kernele (\textit{cuLaunchGrid}), 
(v) The GPU task is synchronized to the GPU kernel (\textit{cuCtxSynchronize}), 
(vi) The resultant data transfer to host memory from device memory (\textit{cuMemcpyDtoH}), 
(vii) release allocated memory space and context (\textit{cuMemFree, cuModuleUnload, cuCtxDestroy}).

We define a GPU task which is to execute the GPU using above API flow,
and define a GPU kernel that is unit of processing to executed on the GPU side.

%我々は本稿においては、GPU実行が少しでも含まれるプロセスであり、ある事柄を成し遂げる一つの単位をアプリケーションとする。 (e.g. pedestrian detection application).
%またこの一連の流れによってGPUを実行する1プロセスをGPUタスクとし、
%GPU側で実行されるカーネルをGPUカーネルと定義する。

\subsection{GPU Scheduling}
Real-time OS (RTOS) is a lot of research\cite{spring, redline,itron,rk} has been conducted for a long time.
In among them have also been many studies\cite{prk,rtai,yodaiken1999rtlinux,litmus,kato:loadable} real-time OS, which is based on the Linux.
%リアルタイムOSは古来より多くの研究\cite{spring,redline,itron,rk}が行われてきている。
%LinuxをベースとしたリアルタイムOSとしても数多く研究\cite{prk,rtai,yodaiken1999rtlinux,litmus,kato:loadable}されている。
%GPUを利用可能な環境はWindows, Mac OS, Linuxと限られており、リアルタイムという性質を追求するためにはLinuxの利用が最適であるため、今回我々はlinuxを利用する。
OS available the GPU is limited to Windows, Mac OS and Linux,
we selected Linux in order to achieve real-time on GPU environments.

Requirement that the scheduler the minimum required in carrying to realize the real-time multi-core environment is the following two:
%マルチコア環境でリアルタイムを実現するにあたりスケジューラが最低限必要とする要件は以下の2つである．
\begin{itemize}
\item To use resources according to order.
%.The mechanisms is resources that are available to the specified order
%u指れた順番でリソースが利用可能なこと
\item To limit the use of the shared resource
\end{itemize}
The basic approach to satisfy the first is priority-based scheduling (e.g. Rate-Monotonic\cite{sched:rm} and Earliest Deadline First\cite{sched:edf}) with technique to prevent priority inversion,
and the second is resource reservation based scheduling (e.g. Constant Bandwidth Server\cite{rr:cbs}, Total Bandwidth Server\cite{rr:tbs2}).
%これらを満たすための基本的なアプローチとして，一つ目は優先度ベースのスケジューリング (e.g. Rate-monotonic, Earliest deadline first)，
%2つ目は，リソースリザベーションベースのスケジューリング (e.g. CBS, TBS, credit)が用いられる．
The GPU to handle the data transfer bandwidth and the processing core as a shared resource,
it is necessary to satisfy the two requirements similar to above multicore environment.
%GPUはデータ転送帯域，プロセッシングコアの2つを共有リソースとして扱う必要性があり，上記マルチコア環境と同様に2つの要件を満たす必要がある．
%Therefore, in the system of including GPU is 
%そのためGPUが含まれるシステムにおいても，リアルタイムを実現するためには上記二点を達成できればよい．
Our previous working only to scheduling GPU accesses.
However, GPU kernel is driven by API is issued GPU task, to truly support  the real-time scheduling, it is need to schedule GPU task; therefore, for realized real-time GPU, framework need to have CPU's priority-based scheduler, GPU's priority-based schedulera and restrict GPU resource by resource reservation mechanisms.
%我々がこれまで取り組んできたGPUリソースマネージメントに関する研究では，
%GPUへのアクセスのみをスケジューリングしてきた．
%しかしながらGPUカーネルはGPUタスクから発行されるAPIを起点に動作していることから，
%真にリアルタイムスケジューリングを適応するためには，GPUタスク自体のスケジューリングを行う必要がある．
%したがって，GPUをリアルタイムにスケジューリングするために必要なメカニズムは，
%CPUの優先度ベーススケジューラ，GPUの優先度ベーススケジューラ，リソースリザベーションによるGPUリソース制限である．
Recently, GPUSync is to work the above interdependence of CPU scheduler and GPU scheduler.
%最近ではGPUSyncが上記のCPUスケジューラとGPUスケジューラの相互依存について取り組んでいる．
%GPUSync needs to install by patch because it depends to $LITMUS^RT$.

%しかし，GPUSyncは$LITMUS^RT$に依存しており，パッチによるインストレーションを必要とする．
%Section~\ref{sec:intro}で述べたとおり，カーネルにパッチを当てる作業は大きな負担になる．
GPUs have some problem on using realtime, except that scheduling mechanisms.
%GPUのリアルタイム活用にはスケジューリングメカニズム以外の面でも多くの問題がある．
GPUs runtime environments are blackbox mechanisms results from GPU environments are provided only GPU vendors and these environments are closed-source.
%まずGPUの実行環境がベンダーから提供されるのみであり，クローズドソースになっていることからブラックボックスであることである．
TimeGraph, Gdev and RGEM are solved this problem by ensuring transparency using reverse engineering and open-source driver.
%本問題についてはTIMEGRAPH，GDEV，RGEMではリバースエンジニアリングとオープンソースドライバによって透明性を確保している．
GPUSync is solved this problem too by GPU runtime resource management is disabled through the runtime access to single.
%GPUSyncではランタイムドライバへのアクセスを単一に制限することで，ランタイムドライバが行う資源管理をスルーしている．

The other problem occurs by non-preemptive GPU executions and non-preemptive data transfers.
several researchs\cite{basaran:preemptive,sparc} realize implovement the responce time by preventing divides the kernel overrun.
%GPUの実行やデータ転送がノンプリエンプティブであることも大きな問題だ．いくつかの研究\cite{}ではカーネルを分割することで，
%ノンプリエンプティブに起因するオーバランを防ぎ，レスポンスタイムの向上を実現している．

As these core problems are headling to solve, however, real-time GPU is experimental-phase since have problem for practical realized.
%このようにいくつかのコアな問題は解決に近づいているが，未だリアルタイムGPUは実験フェーズであり，実用化に向けるには問題が存在している．
The most difficult problem is self-supension due to GPU is treated as a I/O device.
GPU task to suspended themselfs until it receives the results from issuing the processing to GPU, referred to as self-suspension.
%GPUを完全にリアルタイムに扱うことができないもっとも困難な問題は，GPUがI/Oデバイスとして扱われることに起因する．
%GPUに処理を発行し，結果を受け取るまでの間，発行したタスクは自らサスペンドする．
The self-suspension has been proven as a cause the NP-HARD problem in previous work\cite{self-sus:1,self-sus:2},
several researchs\cite{chattopadhyay2014limited, kim2013segment} are working on the scheduling analysis for self-suspension task, but it has not been solved yet to complete.

Hence scheduling framework for the expansion and installation to aim in this study and easy is useful,
it is argued that there is a demand.

%このself-suspensionはこれまでの研究\cite{self-sus:1,self-sus:2}でNP-HARDな問題を発生させるとして証明されており，
%これまでも多くの研究が執り行われている\cite{chattopadhyay2014limited,kim2013segment}が，実用レベルでは未だ解決されていない問題である．

%そのため本研究で目指すような拡張，インストールを容易とするスケジューリングフレームワーク実験レベル，実用レベルの両者において有用であり，需要が発生すると推測する．

\textbf{GPU Synchronization:}
%GPUを利用するシステムのようなヘテロジニアス且つメモリを共有しない場合に大きな課題となるのが同期である
The synchronization matters for GPU system such as heterogeneous platoform.
GPU have two different synchronization techniques.
The first techniques is memory map based synchronization which is called FENCE,
it sends GPU commands after the command to take action,
then GPUs microcontrollers will write the any value to memory-mapped space after action is completed.
GPU task monitors it mapped space value using such as polling,
therefore task has an exclusive CPU resource,
but response time will be the fastest.
The other one techniques is interrupts based synchronization which is called NOTIFY,
it sends GPU commands similar to FENCE,
then GPUs microcontrollers will rise the interrupt and write any value to GPU I/O registers.
GPU task is suspending until interrupt,
therefore task is able to share the CPU resources with other tasks,
but response time will be the slow. Detailed architecture is omitted in this paper,
it has been described in the previous documents\cite{kato:timegprah, kato:gdev, fujii:apsys2013}.

Gdev use both techniques that are NOTIFY and FENCE for wakeup the waiting task,
NOTIFY is used by scheduler, FENCE is used by kernel synchronization. 
Gdev’s synchronization implementation is the addtional commands sends to GPU and the modification of device driver ’s interrupt handler.
GPUSync use NOTIFY techniques by using tasklet intercept\cite{elliott2012robust} on the proprietary software.
Tasklet is linux’s soft-irq implementation.
GPUSync identify the interrupt that is issued which kernel by callback pointer with a tasklet.

\textbf{kernel free scheduler:}
To achieve ”kernel free”,
we must not to modify the kernel code and the device driver code.
GPU スケジューラは次に実行するカーネルの 選択のために,
現在実行中のカーネルの実行が終了したという通知を受け取る必要がある.この受 取には,API-driven と Interrupt-driven な方式が ある.RGEM ではこの API-driven を用いており, cuCtxSynchronize() などのランタイムによって 提供される API によってカーネルが同期された後 に,明示的にスケジューラを起動する API を発行 する.Gdev や TimeGraph では Interrupt-driven を利用しており,NOTIFY を利用する際に発行さ れる割込みをトリガーとしてスケジューラを起動 する.
一般的に用いられる cuCtxSynchroniza() は当 該コンテキストで現在発行されている全てのカー ネルが終了したタイミングで同期する.したがっ て API-driven では一つの GPU コンテキストから は一度に一つのカーネルが発行される場合のみに 対応可能である.
しかしながら,一つの GPU コンテキストから 連続して複数のカーネルが発行されるケースは, 多々発生すると考えられる. その影響から,カー ネル実行のレスポンスタイムが低下し,オーバラ ンの発生率を高める問題が発生する.
Interrupt-driven では NOTIFY で用いられる割 込みを取得するため,各カーネル毎に同期が可能 であるため,スケジューリングを考えた場合には 有効であるが,割込みの取得のために,カーネル もしくはデバイスドライバ内の ISR を直接修正す る必要がある.
Gdev has been achieved independs synchronization mechanisms on the proprietary soft- ware, need to modify the kernel modification. The challenge is realize independs synchroniza- tion mechanisms by kernel free aproach.
